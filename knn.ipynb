{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K- Nearest Neighbours\n",
    "# Steps\n",
    "- First encode categorical columns usign pd.get_dummies(one-hot encoding)\n",
    "- Split the data into training and validation data; use stratify\n",
    "- Create an instance of KNeighborsClassifier\n",
    "- Create a parameter grid\n",
    "- Before training drop useless columns like LoanID\n",
    "- Also scale the input data as knn relies on distance measures\n",
    "- Conduct a randomized search over the param_grid to get best hyper-parameters (train the model). Here n_neighbors is an important parameter\n",
    "- Use the best parameters to provide predictions or labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LoanID', 'Age', 'Income', 'LoanAmount', 'CreditScore',\n",
      "       'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm',\n",
      "       'DTIRatio', 'Education', 'EmploymentType', 'MaritalStatus',\n",
      "       'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner',\n",
      "       'Default'],\n",
      "      dtype='object')\n",
      "\n",
      "Index(['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed',\n",
      "       'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio', 'Education',\n",
      "       'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents',\n",
      "       'LoanPurpose', 'HasCoSigner'],\n",
      "      dtype='object')\n",
      "encoding done\n",
      "Best Parameters: {'weights': 'uniform', 'n_neighbors': 50, 'metric': 'minkowski', 'leaf_size': 50, 'algorithm': 'ball_tree'}\n",
      "Training accuracy 0.8841336180784599\n",
      "Validation accuracy 0.8837380066575289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "test_df  = pd.read_csv('./data/test.csv')\n",
    "ids = test_df['LoanID']\n",
    "test_df = test_df.drop(columns='LoanID')\n",
    "print(df.columns)\n",
    "print()\n",
    "print(test_df.columns)\n",
    "\n",
    "# we need to  encode each categorical column\n",
    "to_encode = []\n",
    "for column in df.columns:\n",
    "    if column == 'LoanID':\n",
    "        continue\n",
    "    if df[column].dtype == 'object':\n",
    "        to_encode.append(column)\n",
    "    elif df[column].dtype not in ['float64', 'int64', 'float', 'int']:\n",
    "        to_encode.append(column)\n",
    "# for column in to_encode:\n",
    "#     le = LabelEncoder() #for now let's use labelEncoder\n",
    "#     df[column] = le.fit_transform(df[column])\n",
    "#     test_df[column] = le.transform(test_df[column])\n",
    "    # later use le.inverse_transform if needed\n",
    "\n",
    "#one hot\n",
    "df = pd.get_dummies(df, columns=to_encode, drop_first=True, dtype=int)\n",
    "test_df = pd.get_dummies(test_df, columns=to_encode, drop_first=True, dtype=int)\n",
    "\n",
    "print('encoding done')\n",
    "\n",
    "\n",
    "# now all the categorical columns are set\n",
    "df = df.drop(columns=['LoanID'])\n",
    "\n",
    "train_df, validation_df = train_test_split(df, test_size=0.2, random_state=17,stratify=df['Default'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "x_train_df = train_df.drop(columns=['Default'])\n",
    "y_train_df = train_df['Default']\n",
    "\n",
    "scaler.fit_transform(x_train_df)\n",
    "x_validation_df = validation_df.drop(columns=['Default'])\n",
    "y_validation_df = validation_df['Default']\n",
    "\n",
    "scaler.transform(x_validation_df)\n",
    "scaler.transform(test_df)\n",
    "\n",
    "\n",
    "# class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [40, 50, 60],  # 50 is the best \n",
    "    # \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    \"algorithm\": ['auto', 'ball_tree'],\n",
    "    \"weights\": ['uniform','distance'],\n",
    "    \"leaf_size\": [20, 30, 50],\n",
    "    # \"p\": [1, 2],\n",
    "    \"metric\": ['minkowski', 'euclidean'],\n",
    "}\n",
    "\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=knn_clf, param_distributions=param_grid, random_state=17)\n",
    "# rs = GridSearchCV(estimator=knn_clf,param_grid=param_grid)\n",
    "rs.fit(x_train_df, y_train_df)\n",
    "print(\"Best Parameters:\", rs.best_params_)\n",
    "\n",
    "\n",
    "# tree_clf.fit(x_train_df, y_train_df)\n",
    "\n",
    "# y_pred = tree_clf.predict(x_validation_df)\n",
    "y_pred = rs.predict(x_validation_df)\n",
    "\n",
    "train_acc = accuracy_score(y_train_df, rs.predict(x_train_df))\n",
    "valid_acc = accuracy_score(y_validation_df, y_pred)\n",
    "\n",
    "print(f'Training accuracy {train_acc}')\n",
    "print(f'Validation accuracy {valid_acc}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "newdf = pd.DataFrame({\"LoanID\": ids, \"Default\": rs.predict(X=test_df)})\n",
    "newdf.to_csv('./csv_submissions/knn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
